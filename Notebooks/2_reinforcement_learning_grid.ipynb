{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50fa2863",
   "metadata": {},
   "source": [
    "# Sub-task 2: Reinforcement Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc6d212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal policy for state (1, 0): UP with expected utility 7.29\n",
      "Optimal policy for state (4, 2): LEFT with expected utility 6.64\n",
      "Optimal policy for state (3, 2): DOWN with expected utility 6.44\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the grid with utilities\n",
    "grid_utilities = np.array([\n",
    "    [7.41, 7.52, 7.65, 10, 7.54],\n",
    "    [7.31, np.nan, -10, 5.82, -10],\n",
    "    [7.15, np.nan, 4.31, np.nan, 6.12],\n",
    "    [6.98, 6.77, 6.44, 5.87, np.nan],\n",
    "    [6.90, 6.80, 6.59, 6.51, 6.34]\n",
    "])\n",
    "\n",
    "# Define the reward for non-terminal states\n",
    "reward = -0.1\n",
    "\n",
    "# Define the state transition probabilities\n",
    "prob_success = 0.8\n",
    "prob_fail = 0.1  # 0.2 probability of failure divided equally between two perpendicular directions\n",
    "\n",
    "# Function to calculate the expected utility of a move\n",
    "def expected_utility(grid, state, action):\n",
    "    x, y = state\n",
    "    if action == \"UP\":\n",
    "        intended_state = (x - 1, y)\n",
    "    elif action == \"DOWN\":\n",
    "        intended_state = (x + 1, y)\n",
    "    elif action == \"LEFT\":\n",
    "        intended_state = (x, y - 1)\n",
    "    elif action == \"RIGHT\":\n",
    "        intended_state = (x, y + 1)\n",
    "    \n",
    "    # Check for invalid moves\n",
    "    if intended_state[0] < 0 or intended_state[0] >= grid.shape[0] or \\\n",
    "       intended_state[1] < 0 or intended_state[1] >= grid.shape[1] or \\\n",
    "       np.isnan(grid[intended_state]):\n",
    "        intended_utility = grid[state]\n",
    "    else:\n",
    "        intended_utility = grid[intended_state]\n",
    "    \n",
    "    # Calculate utilities for perpendicular moves\n",
    "    fail_utilities = []\n",
    "    for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]:  # UP, DOWN, LEFT, RIGHT\n",
    "        fail_state = (x + dx, y + dy)\n",
    "        if fail_state == intended_state or \\\n",
    "           fail_state[0] < 0 or fail_state[0] >= grid.shape[0] or \\\n",
    "           fail_state[1] < 0 or fail_state[1] >= grid.shape[1] or \\\n",
    "           np.isnan(grid[fail_state]):\n",
    "            fail_utilities.append(grid[state])\n",
    "        else:\n",
    "            fail_utilities.append(grid[fail_state])\n",
    "    \n",
    "    # Assuming perpendicular moves are LEFT and RIGHT or UP and DOWN\n",
    "    perpendicular_utilities = (fail_utilities[2] + fail_utilities[3]) if action in [\"UP\", \"DOWN\"] \\\n",
    "                              else (fail_utilities[0] + fail_utilities[1])\n",
    "    \n",
    "    # Calculate the expected utility\n",
    "    eu = (prob_success * intended_utility) + (prob_fail * perpendicular_utilities) + reward\n",
    "    \n",
    "    return eu\n",
    "\n",
    "# The highlighted states are (1, 0), (4, 2), and (3, 2)\n",
    "highlighted_states = [(1, 0), (4, 2), (3, 2)]\n",
    "\n",
    "# Calculate the optimal policy for each highlighted state\n",
    "optimal_policies = {}\n",
    "for state in highlighted_states:\n",
    "    actions = [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\"]\n",
    "    utilities = {action: round(expected_utility(grid_utilities, state, action), 2) for action in actions}\n",
    "    optimal_action = max(utilities, key=utilities.get)\n",
    "    optimal_policies[state] = optimal_action\n",
    "\n",
    "# Output the optimal policies and their expected utilities for the highlighted states\n",
    "for state, action in optimal_policies.items():\n",
    "    expected_utility_value = round(expected_utility(grid_utilities, state, action), 2)\n",
    "    print(f\"Optimal policy for state {state}: {action} with expected utility {expected_utility_value}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
